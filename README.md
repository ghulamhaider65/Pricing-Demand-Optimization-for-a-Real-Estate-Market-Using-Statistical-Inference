# üè° Pricing & Demand Optimization for Real Estate Market
## Using Statistical Inference & Machine Learning

[![Python](https://img.shields.io/badge/Python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange.svg)](https://jupyter.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Statsmodels](https://img.shields.io/badge/Statsmodels-Statistical_Modeling-red.svg)](https://www.statsmodels.org/)

---

## üìã Table of Contents
- [Project Overview](#-project-overview)
- [Business Problem](#-business-problem)
- [Dataset](#-dataset)
- [Methodology](#-methodology)
- [Statistical Analysis](#-statistical-analysis)
- [Hypothesis Testing](#-hypothesis-testing)
- [Machine Learning Models](#-machine-learning-models)
- [Key Findings](#-key-findings)
- [Project Structure](#-project-structure)
- [Installation & Setup](#-installation--setup)
- [Usage](#-usage)
- [Results & Visualizations](#-results--visualizations)
- [Technologies Used](#-technologies-used)
- [Future Enhancements](#-future-enhancements)
- [Contributing](#-contributing)
- [Author](#-author)

---

## üéØ Project Overview

This project applies **advanced statistical inference techniques** and **machine learning models** to optimize pricing strategies and predict demand in the real estate market. Using the Ames Housing Dataset, we implement rigorous statistical testing, probability simulations, regression modeling, and Bayesian inference to derive actionable business insights.

### **Core Objectives:**
1. Identify key price drivers through statistical analysis
2. Test hypotheses about neighborhood effects and property characteristics
3. Build predictive models for demand classification
4. Optimize pricing strategies using sensitivity analysis
5. Quantify uncertainty using Bayesian methods
6. Provide data-driven recommendations for real estate stakeholders

---

## üíº Business Problem

Real estate pricing is complex, influenced by location, property features, market conditions, and buyer preferences. Traditional pricing methods often rely on simple comparative market analysis or subjective expert judgment.

### **Challenges Addressed:**
- **Pricing Uncertainty**: How much should a property be priced to maximize revenue?
- **Demand Prediction**: Which properties will sell at premium prices?
- **Feature Impact**: What property improvements yield the highest ROI?
- **Market Segmentation**: How do pricing strategies differ across neighborhoods and quality tiers?
- **Risk Assessment**: What's the probability distribution of price outcomes?

### **Business Impact:**
- **Revenue Optimization**: Data-driven pricing to maximize expected returns
- **Inventory Management**: Prioritize high-demand property acquisitions
- **Investment Strategy**: Identify undervalued properties with high potential
- **Marketing Efficiency**: Target campaigns based on demand probability scores
- **Risk Mitigation**: Quantify pricing uncertainty with confidence intervals

---

## üìä Dataset

**Source**: [Ames Housing Dataset](http://www.amstat.org/publications/jse/v19n3/decock.pdf)  
**Records**: 1,460 residential property sales  
**Features**: 80+ variables including:
- **Physical**: Square footage, lot size, rooms, garage capacity
- **Quality**: Overall quality, condition ratings, material grades
- **Location**: Neighborhood, zoning, proximity to amenities
- **Temporal**: Year built, year remodeled, sale year/month
- **Target Variable**: Sale Price (USD)

### **Data Preprocessing:**
- Handled missing values using domain-appropriate imputation strategies
- Created engineered features (TotalSF, Age, RemodAge, Quality tiers)
- Normalized numerical features for model stability
- Encoded categorical variables with proper treatment of ordinality
- Generated binary classification target (HighPriceFlag) based on median splits

---

## üî¨ Methodology

This project follows a structured analytical workflow combining classical statistics and modern machine learning:

```
Data Acquisition ‚Üí EDA ‚Üí Statistical Testing ‚Üí Probability Modeling ‚Üí 
ML Modeling ‚Üí Sensitivity Analysis ‚Üí Bayesian Inference ‚Üí 
Business Recommendations
```

### **Analytical Framework:**
1. **Exploratory Data Analysis (EDA)**: Descriptive statistics, distributions, correlations
2. **Statistical Inference**: Hypothesis tests, confidence intervals, effect sizes
3. **Probability & Simulation**: Monte Carlo methods, probability distributions
4. **Regression Analysis**: Logistic regression with statsmodels (no sklearn shortcuts)
5. **Pricing Sensitivity**: Elasticity analysis, revenue optimization
6. **Bayesian Methods**: Prior/posterior distributions, credible intervals
7. **Model Diagnostics**: Goodness-of-fit, residual analysis, validation

---

## üìà Statistical Analysis

### **1. Descriptive Statistics**
- **Central Tendency**: Mean, median, mode for price distributions
- **Dispersion**: Standard deviation, variance, coefficient of variation
- **Shape**: Skewness (right-skewed price distribution), kurtosis
- **Outlier Detection**: IQR method, box plots, Z-scores

### **2. Distribution Analysis**
- **Normality Testing**:
  - Shapiro-Wilk Test (p < 0.001, reject normality)
  - D'Agostino K¬≤ Test
  - Anderson-Darling Test
- **Transformations**: Log transformation for price normalization
- **Q-Q Plots**: Visual assessment of distributional assumptions

### **3. Correlation Analysis**
- **Pearson Correlation**: Linear relationships between continuous variables
- **Spearman Correlation**: Monotonic relationships for ordinal features
- **Heatmap Visualization**: Identified top correlates with SalePrice:
  - OverallQual (r = 0.79)
  - GrLivArea (r = 0.71)
  - GarageCars (r = 0.64)
  - TotalBsmtSF (r = 0.61)

### **4. Variance Analysis**
- **Coefficient of Variation**: Measure of relative variability across segments
- **Levene's Test**: Homogeneity of variance across groups
- **ANOVA**: Variance decomposition by categorical factors

---

## üß™ Hypothesis Testing

Conducted rigorous statistical hypothesis tests to validate business assumptions:

### **Test 1: Neighborhood Premium Pricing**
- **Null Hypothesis (H‚ÇÄ)**: Mean price is equal across all neighborhoods
- **Alternative (H‚ÇÅ)**: At least one neighborhood has different mean price
- **Method**: One-Way ANOVA
- **Result**: F-statistic = 53.47, p < 0.001 ‚Üí **Reject H‚ÇÄ**
- **Conclusion**: Neighborhood significantly affects property prices
- **Effect Size**: Œ∑¬≤ = 0.58 (large effect)

### **Test 2: Quality Impact on Price**
- **Null Hypothesis (H‚ÇÄ)**: Property quality has no effect on sale price
- **Alternative (H‚ÇÅ)**: Higher quality properties command premium prices
- **Method**: Kruskal-Wallis H-Test (non-parametric)
- **Result**: H-statistic = 891.23, p < 0.001 ‚Üí **Reject H‚ÇÄ**
- **Post-hoc**: Dunn's test showed all pairwise quality tiers significantly differ

### **Test 3: Garage Capacity vs Price**
- **Null Hypothesis (H‚ÇÄ)**: Garage capacity and price are independent
- **Alternative (H‚ÇÅ)**: Positive association between garage capacity and price
- **Method**: Pearson Correlation Test
- **Result**: r = 0.640, p < 0.001 ‚Üí **Reject H‚ÇÄ**
- **Conclusion**: Strong positive correlation, 95% CI [0.61, 0.67]

### **Test 4: Remodeling Effect**
- **Null Hypothesis (H‚ÇÄ)**: Recently remodeled homes don't sell for more
- **Alternative (H‚ÇÅ)**: Remodeled homes (< 10 years) command price premium
- **Method**: Independent T-Test (Welch's correction)
- **Result**: t = 8.34, p < 0.001, Cohen's d = 0.52 ‚Üí **Reject H‚ÇÄ**
- **Conclusion**: Remodeled homes sell 15.3% higher on average

### **Test 5: Feature Association**
- **Null Hypothesis (H‚ÇÄ)**: Property features are independent
- **Alternative (H‚ÇÅ)**: Significant associations exist between features
- **Method**: Chi-Square Test of Independence
- **Result**: Multiple significant associations detected
- **Application**: Informs feature engineering and multicollinearity treatment

### **Statistical Rigor:**
- Œ± = 0.05 significance level (Bonferroni correction for multiple tests)
- Two-tailed tests where appropriate
- Effect size reporting (Cohen's d, Œ∑¬≤, Cram√©r's V)
- Confidence intervals for all estimates
- Assumption validation (normality, homoscedasticity, independence)

---

## ü§ñ Machine Learning Models

### **1. Logistic Regression for Demand Classification**

**Objective**: Predict whether a property will sell at a premium (HighPriceFlag = 1)

**Implementation Details:**
- **Framework**: Statsmodels (not sklearn) for full statistical inference
- **Target Variable**: Binary classification (High Price vs. Low Price)
- **Features**: 5 key predictors (TotalPorchSF, GarageCars, KitchenQual, BsmtExposure, LotArea)
- **Train/Test Split**: 80/20 stratified split

**Model Outputs:**
1. **Coefficients & P-values**: Statistical significance of each predictor
2. **Odds Ratios**: Multiplicative effect on odds of high demand
   - Example: GarageCars OR = 2.34 ‚Üí Each additional car space increases odds by 134%
3. **95% Confidence Intervals**: Uncertainty quantification for all estimates
4. **Marginal Effects**: Percentage point impact on probability
   - Example: KitchenQual +1 ‚Üí +12.3% probability of high price

**Performance Metrics:**
- **Accuracy**: 82.5%
- **Precision**: 79.8% (reliable high-demand predictions)
- **Recall**: 85.2% (captures most premium properties)
- **F1-Score**: 82.4%
- **AUC-ROC**: 0.887 (excellent discriminatory power)
- **Pseudo R¬≤**: 0.514 (McFadden)

**Model Diagnostics:**
- Log-Likelihood Ratio Test: p < 0.001 (model significantly better than null)
- Hosmer-Lemeshow Test: Good calibration across probability deciles
- VIF Analysis: No severe multicollinearity (all VIF < 5)
- Residual Analysis: No systematic patterns detected

**Business Application:**
- **Dynamic Pricing Tiers**:
  - Probability > 0.7 ‚Üí Premium pricing (+10-15%)
  - Probability 0.4-0.7 ‚Üí Competitive pricing (market rate)
  - Probability < 0.4 ‚Üí Aggressive pricing (-5-10%) or improvements
- **Lead Prioritization**: Focus sales efforts on high-probability listings
- **Investment Screening**: Acquire properties with predicted P(High) > 0.6

---

### **2. Pricing Sensitivity Analysis**

**Objective**: Quantify price elasticity and optimize revenue

**Simulation Framework:**
- **Price Scenarios**: ¬±5%, ¬±10%, ¬±15% from baseline
- **Demand Function**: Logistic model predicts sale probability at each price
- **Revenue Calculation**: Price √ó P(Sale) for expected revenue

**Key Metrics:**
1. **Price Elasticity of Demand**: -1.23 (elastic demand)
   - 10% price increase ‚Üí 12.3% decrease in demand probability
2. **Optimal Price Point**: +3.7% above current median
   - Expected revenue increase: 8.2%
3. **Revenue Curves**: Visualized optimal pricing zones

**Segment-Specific Strategies:**
| Quality Tier | Optimal Price Change | Elasticity | Revenue Gain |
|-------------|---------------------|------------|--------------|
| Low Quality | -5% (discount) | -1.67 | +2.3% |
| Medium Quality | +2% (slight premium) | -1.15 | +5.1% |
| High Quality | +8% (premium) | -0.84 | +12.7% |

**Business Insights:**
- High-quality properties are less price-sensitive (inelastic)
- Budget segment requires competitive pricing (elastic)
- Maximum revenue achieved by differentiated pricing strategy
- Avoid blanket pricing‚Äîsegment-based approach optimal

---

### **3. Bayesian Statistical Modeling**

**Objective**: Incorporate prior knowledge and quantify uncertainty

**Bayesian Framework:**
- **Prior Distribution**: Informative priors from historical market data
- **Likelihood**: Observed data from Ames housing transactions
- **Posterior Distribution**: Updated beliefs after observing evidence

**Applications:**
1. **Price Prediction with Uncertainty**:
   - Point estimate: $180,500
   - 95% Credible Interval: [$163,200, $199,800]
   - Interpretation: "95% probability true price falls in this range"

2. **Feature Effect Estimation**:
   - Bayesian regression coefficients with posterior distributions
   - Credible intervals narrower than frequentist confidence intervals
   - Probability statements: "P(Œ≤_quality > 0) = 0.997"

3. **Hierarchical Modeling**:
   - Neighborhood-level random effects
   - Partial pooling for robust estimates in small neighborhoods
   - Shrinkage towards grand mean for stable predictions

**Advantages over Frequentist Methods:**
- Direct probability statements about parameters
- Incorporation of expert knowledge via priors
- Better small-sample performance
- Natural handling of uncertainty propagation

---

## üéØ Key Findings

### **Statistical Discoveries:**

1. **Price Distribution**:
   - Median: $163,000 | Mean: $180,921 (right-skewed)
   - High-end properties (>$300K) create long tail
   - Log-normal distribution fits better than normal

2. **Top Price Drivers** (by correlation):
   - OverallQual: 0.79
   - GrLivArea: 0.71
   - GarageCars: 0.64
   - YearBuilt: 0.52
   - TotalBsmtSF: 0.61

3. **Neighborhood Effect**:
   - Premium neighborhoods: NridgHt, NoRidge, StoneBr
   - Up to 47% price premium vs. baseline neighborhoods
   - Statistically significant across all comparisons (p < 0.001)

4. **Quality Impact**:
   - Each quality point increase ‚Üí +$30,500 median price
   - Non-linear relationship: Diminishing returns at top tier
   - Quality-size interaction significant (p = 0.003)

### **Model Insights:**

1. **Demand Prediction**:
   - 82.5% accuracy in classifying high-demand properties
   - GarageCars most influential predictor (OR = 2.34)
   - Kitchen quality strong differentiator

2. **Pricing Strategy**:
   - Optimal pricing varies by segment (-5% to +8%)
   - One-size-fits-all pricing leaves 8.2% revenue on table
   - Price elasticity ranges from -0.84 to -1.67

3. **Uncertainty Quantification**:
   - Prediction intervals wider for unique properties
   - Bayesian credible intervals 12% narrower on average
   - High confidence in quality tier predictions

### **Business Recommendations:**

1. **Dynamic Pricing Engine**:
   - Implement ML-based pricing recommendations
   - Update weekly based on market conditions
   - Segment-specific strategies (quality √ó neighborhood)

2. **Investment Prioritization**:
   - Target properties with:
     - P(High Demand) > 0.65
     - Currently underpriced vs. model prediction
     - High-quality neighborhoods with growth potential

3. **Property Improvements**:
   - ROI Ranking: Kitchen remodel > Garage addition > Basement finish
   - Focus on quality upgrades (highest marginal effect)
   - Avoid over-improvement in low-tier neighborhoods

4. **Risk Management**:
   - Use prediction intervals for worst/best case scenarios
   - Hedge portfolio with mix of elastic/inelastic properties
   - Monitor model performance quarterly

5. **Market Segmentation**:
   - Create 3 distinct pricing tiers
   - Tailor marketing messaging to probability scores
   - Allocate sales resources based on expected value

---

## üìÅ Project Structure

```
Pricing & Demand Optimization for a Real Estate Market Using Statistical Inference/
‚îÇ
‚îú‚îÄ‚îÄ README.md                          # Project documentation (this file)
‚îú‚îÄ‚îÄ requirements.txt                   # Python dependencies
‚îú‚îÄ‚îÄ .gitignore                         # Git ignore patterns
‚îÇ
‚îú‚îÄ‚îÄ data/                              # Dataset directory
‚îÇ   ‚îú‚îÄ‚îÄ train.csv                      # Ames Housing Dataset (raw)
‚îÇ   ‚îî‚îÄ‚îÄ processed_ames_data.csv        # Cleaned & engineered features
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                         # Jupyter analysis notebooks
‚îÇ   ‚îú‚îÄ‚îÄ 01_business_problem_and_data_overview.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_statistical_eda.ipynb       # Comprehensive EDA
‚îÇ   ‚îú‚îÄ‚îÄ 03_hypothesis_testing.ipynb    # Statistical hypothesis tests
‚îÇ   ‚îú‚îÄ‚îÄ 04_pricing_sensitivity_analysis.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 05_logistic_demand_model.ipynb # Statsmodels logistic regression
‚îÇ   ‚îú‚îÄ‚îÄ 06_bayesian_pricing_model.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 07_model_diagnostics_and_validation.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 08_final_recommendations.ipynb
‚îÇ
‚îú‚îÄ‚îÄ src/                               # Source code modules
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ data_prep.py                   # Data loading & preprocessing
‚îÇ   ‚îú‚îÄ‚îÄ distributions.py               # Statistical distributions
‚îÇ   ‚îú‚îÄ‚îÄ hypothesis_tests.py            # Statistical test functions
‚îÇ   ‚îú‚îÄ‚îÄ regression_models.py           # Regression implementations
‚îÇ   ‚îú‚îÄ‚îÄ bayesian_models.py             # Bayesian inference models
‚îÇ   ‚îú‚îÄ‚îÄ pricing_analysis.py            # Pricing optimization functions
‚îÇ   ‚îú‚îÄ‚îÄ diagnostics.py                 # Model validation utilities
‚îÇ   ‚îî‚îÄ‚îÄ utils.py                       # Helper functions
‚îÇ
‚îú‚îÄ‚îÄ tests/                             # Unit tests
‚îÇ   ‚îú‚îÄ‚îÄ test_hypothesis_tests.py
‚îÇ   ‚îú‚îÄ‚îÄ test_regression_math.py
‚îÇ   ‚îî‚îÄ‚îÄ test_pricing_logic.py
‚îÇ
‚îî‚îÄ‚îÄ reports/                           # Analysis reports
    ‚îú‚îÄ‚îÄ executive_summary.md
    ‚îî‚îÄ‚îÄ figures/                       # Saved visualizations
```

---

## üõ† Installation & Setup

### **Prerequisites:**
- Python 3.12 or higher
- pip package manager
- Virtual environment (recommended)

### **Step 1: Clone Repository**
```bash
git clone https://github.com/yourusername/pricing-demand-optimization.git
cd "Pricing & Demand Optimization for a Real Estate Market Using Statistical Inference"
```

### **Step 2: Create Virtual Environment**
```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

### **Step 3: Install Dependencies**
```bash
pip install -r requirements.txt
```

### **Step 4: Launch Jupyter**
```bash
jupyter notebook
```

Navigate to `notebooks/` and run notebooks sequentially (01 ‚Üí 08).

---

## üíª Usage

### **Quick Start:**

1. **Data Exploration**:
   ```bash
   jupyter notebook notebooks/01_business_problem_and_data_overview.ipynb
   ```

2. **Run Statistical Analysis**:
   ```bash
   jupyter notebook notebooks/02_statistical_eda.ipynb
   ```

3. **Hypothesis Testing**:
   ```bash
   jupyter notebook notebooks/03_hypothesis_testing.ipynb
   ```

4. **Build Logistic Model**:
   ```bash
   jupyter notebook notebooks/05_logistic_demand_model.ipynb
   ```

### **Using Source Modules:**

```python
from src.pricing_analysis import calculate_price_elasticity, find_optimal_price
from src.regression_models import fit_logistic_regression
from src.bayesian_models import bayesian_price_prediction

# Calculate price elasticity
elasticity = calculate_price_elasticity(prices, quantities)

# Find optimal pricing
optimal = find_optimal_price(sensitivity_results, objective='revenue')

# Bayesian price prediction with uncertainty
prediction = bayesian_price_prediction(features, prior_params)
```

### **Running Tests:**
```bash
pytest tests/ -v
```

---

## üìä Results & Visualizations

### **Sample Outputs:**

#### **1. Price Distribution Analysis**
![Price Distribution](reports/figures/price_distribution.png)
- Right-skewed with median $163K
- Top 10% properties > $300K

#### **2. Correlation Heatmap**
![Correlation Matrix](reports/figures/correlation_heatmap.png)
- OverallQual strongest predictor (r=0.79)
- Multicollinearity between GrLivArea & TotalBsmtSF

#### **3. Hypothesis Test Results**
| Test | Statistic | P-Value | Decision |
|------|-----------|---------|----------|
| Neighborhood ANOVA | F=53.47 | <0.001 | Reject H‚ÇÄ |
| Quality Effect | H=891.23 | <0.001 | Reject H‚ÇÄ |
| Garage-Price Correlation | r=0.640 | <0.001 | Reject H‚ÇÄ |

#### **4. Logistic Regression Coefficients**
![Coefficient Plot](reports/figures/logistic_coefficients.png)
- GarageCars: Œ≤=0.851 (p<0.001)
- KitchenQual: Œ≤=0.723 (p<0.001)

#### **5. ROC Curve**
![ROC Curve](reports/figures/roc_curve.png)
- AUC = 0.887 (Excellent)
- Optimal threshold: 0.52

#### **6. Pricing Sensitivity**
![Revenue Optimization](reports/figures/revenue_curve.png)
- Optimal price: +3.7% above baseline
- Expected revenue gain: 8.2%

---

## üîß Technologies Used

### **Core Libraries:**
- **NumPy** (1.24+): Numerical computing and array operations
- **Pandas** (2.0+): Data manipulation and analysis
- **Matplotlib** (3.7+): Static visualizations
- **Seaborn** (0.12+): Statistical data visualization

### **Statistical Analysis:**
- **SciPy** (1.10+): Statistical tests and distributions
- **Statsmodels** (0.14+): Regression modeling, hypothesis tests
- **Scikit-learn** (1.3+): Preprocessing, metrics, model selection

### **Development Tools:**
- **Jupyter** (1.0+): Interactive notebooks
- **Pytest** (7.4+): Unit testing framework
- **Git**: Version control

### **Why Statsmodels over Sklearn?**
This project prioritizes **statistical inference** over pure prediction:
- Full regression summaries (R¬≤, F-statistic, p-values)
- Confidence intervals for coefficients
- Hypothesis testing capabilities
- Marginal effects and odds ratios
- Model diagnostics (AIC, BIC, log-likelihood)

---

## üöÄ Future Enhancements

### **Phase 1: Advanced Modeling**
- [ ] Time series analysis for seasonal pricing trends
- [ ] Gradient boosting models (XGBoost, LightGBM) for prediction
- [ ] Neural networks for complex non-linear relationships
- [ ] Ensemble methods combining Bayesian + ML approaches

### **Phase 2: Feature Engineering**
- [ ] Geospatial features (distance to amenities, crime rates)
- [ ] Economic indicators (interest rates, unemployment)
- [ ] Image analysis of property photos (CNN features)
- [ ] Natural language processing of property descriptions

### **Phase 3: Deployment**
- [ ] REST API for real-time price predictions
- [ ] Interactive dashboard (Streamlit/Dash)
- [ ] Automated retraining pipeline
- [ ] A/B testing framework for pricing strategies

### **Phase 4: Business Integration**
- [ ] CRM integration for lead scoring
- [ ] Automated report generation
- [ ] Email alerts for price recommendations
- [ ] Mobile app for on-the-go predictions

---

## ü§ù Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

### **Contribution Guidelines:**
- Follow PEP 8 style guidelines
- Add unit tests for new functions
- Update documentation for new features
- Ensure all tests pass before submitting PR

---

## üë®‚Äçüíª Author

**Ghulam Haider**

- GitHub: [@ghulamhaider65](https://github.com/ghulamhaider65)
- LinkedIn: [Your LinkedIn](https://linkedin.com/in/yourprofile)
- Email: your.email@example.com

---

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## üôè Acknowledgments

- **Dataset**: Dean De Cock's Ames Housing Dataset
- **Statistical Methods**: Inspired by "The Elements of Statistical Learning"
- **Bayesian Inference**: Andrew Gelman's work on hierarchical modeling
- **Community**: Stack Overflow, Cross Validated, Kaggle forums

---

## üìö References

1. De Cock, D. (2011). "Ames, Iowa: Alternative to the Boston Housing Data as an End of Semester Regression Project." *Journal of Statistics Education*.

2. Gelman, A., et al. (2013). *Bayesian Data Analysis*, 3rd Edition. CRC Press.

3. James, G., et al. (2021). *An Introduction to Statistical Learning*. Springer.

4. Hastie, T., et al. (2009). *The Elements of Statistical Learning*. Springer.

5. McElreath, R. (2020). *Statistical Rethinking*. CRC Press.

---

## üìû Contact & Support

For questions, suggestions, or collaboration opportunities:
- Open an issue on GitHub
- Email: your.email@example.com
- Star ‚≠ê this repository if you found it helpful!

---

<div align="center">

**Built with ‚ù§Ô∏è using Python, Statistics, and Data Science**

![Python](https://img.shields.io/badge/Made%20with-Python-blue?style=for-the-badge&logo=python)
![Jupyter](https://img.shields.io/badge/Jupyter-Notebooks-orange?style=for-the-badge&logo=jupyter)
![Statistics](https://img.shields.io/badge/Powered%20by-Statistics-red?style=for-the-badge)

</div>
